{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f468e29-702b-4f3e-a0cd-3b1461c29397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c451e898732c:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa56e2fead0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat, lit, avg, round, unix_timestamp, when, split\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cacc03-47b7-4c20-8e44-0dcba3fed026",
   "metadata": {},
   "source": [
    "### We have commented every action performed during the development of the code to reduce to the minimum the execution time\n",
    "To know the number of cores that are being used to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5104b4a-ec07-4a36-b8bc-a9da74bcd5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889e7ba-d0df-4bc3-9e44-aabad03bfaed",
   "metadata": {},
   "source": [
    "We load the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0a5d0e-24de-45e5-be51-ecc877a7e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"timestampFormat\",\"yyyy-MM-dd HH:mm:ss\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").load(\"tripdata_2017_01.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c71a11-708a-4a01-816f-bd681a88662f",
   "metadata": {},
   "source": [
    "We count the rows to verify the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf3b7d3-7f6f-459d-981b-259ab67982ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb1b82-5aa5-46c4-b0c5-12740adc367e",
   "metadata": {},
   "source": [
    "For development purposes, we have been using a new dataframe \"small\", although the final execution has been done using the whole dataframe. Here, a single file of 1000 rows is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38fa2e82-0562-41a5-a3a2-61edb61aa73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r small\n",
    "df.limit(10000).write.option(\"header\", True).option(\"timestampFormat\",\"yyyy-MM-dd HH:mm:ss\").csv(\"small\")   #specifying the csv is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a0675-644f-4377-bdbc-eb5d50f32b0c",
   "metadata": {},
   "source": [
    "## CASE STUDIES\n",
    "- Tips depending on the route\n",
    "- Average speed of taxis in terms of the hour.\n",
    "- Average trip distance group by number of passengers (depending on the number of passengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7ed70-e179-49e7-bea8-ff34fa131dcb",
   "metadata": {},
   "source": [
    "### 1. Tips depending on the route (based on PULocation and DOLocation) \n",
    "\n",
    "#### Solution implemented using dataframes\n",
    "\n",
    "First, we read the csv to be used applying dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3170354b-4b25-4d08-b88a-00a961456475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"timestampFormat\",\"yyyy-MM-dd HH:mm:ss\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").load(\"tripdata_2017_01.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6e9bf-ce46-44c0-9727-b7c654f43f9a",
   "metadata": {},
   "source": [
    "To visualize the data, we list all columns that are part of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c419b9-d1ad-4e70-9764-aa96cb202721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832bf46-12a6-4f99-8499-39bd7604be72",
   "metadata": {},
   "source": [
    "For a better visualization, we transform the dataframe into a Pandas object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07fa1cc7-d5b1-4672-a5ee-00e328d40f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_pandas = df3.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe12583-e474-4d28-8d9b-7558a25901eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ec4f3-027f-4a37-9b9b-01e02fc329dd",
   "metadata": {},
   "source": [
    "We read another dataframe that contains the data associating the location IDs with their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499c9aba-acb8-42f8-a67e-f1d17ce8bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"timestampFormat\",\"yyyy-MM-dd HH:mm:ss\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").load(\"taxi+_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66e069-6636-476a-a16e-e2877c401d80",
   "metadata": {},
   "source": [
    "We select the columns we are interested in from the location dataset: LocationID and Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee0c476-8dad-4361-aadf-0a15af923be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_loc = df_locations.select(\"LocationID\", \"Borough\")\n",
    "#columns_loc.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa1965-66c0-46c9-99d1-3709ef4d7c11",
   "metadata": {},
   "source": [
    "Now we join the original and the locations dataframes where the Location IDs match (DOLocationID = LocationID, and later we perform the join with the PULocationID column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15c94f2-2b94-4c16-a26e-2b2837b7f967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join = df3.join(columns_loc, df3[\"DOLocationID\"] == columns_loc[\"LocationID\"])\n",
    "#df_join.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5450f1b-cd05-45c6-b8e4-3b60d054db32",
   "metadata": {},
   "source": [
    "We renamed the chosen \"Borough\" column as \"ArrivalZone\" and delete the columns we do not want anymore: LocationID and DOLocationID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bb5e44-da50-4a9e-b604-bf7b2c048bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_join.withColumnRenamed(\"Borough\", \"ArrivalZone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6a5f9f-dda3-46d4-b5d5-5ebcb04f27ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join = df_join.drop(\"LocationID\", \"DOLocationID\")\n",
    "#df_join.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7b2bc-ee7c-41cb-a5e5-095ad378a07e",
   "metadata": {},
   "source": [
    "Now, we perform a second join to combine both dataframes where PULocationID = LocationID. We rename the \"Borough\" column as the \"DepartureZone\" and delete the columns we do not want anymore: LocationID and PULocationID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4916329b-f624-4ac5-8385-ec7de97b1a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = df_join.join(columns_loc, df_join[\"PULocationID\"] == columns_loc[\"LocationID\"])\n",
    "#final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99eec59-6274-4946-8c35-8e438965171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.withColumnRenamed(\"Borough\", \"DepartureZone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab06e05-cb96-4e0a-a5a6-6fa8b5db76c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.drop(\"LocationID\", \"PULocationID\")\n",
    "#final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f2ff2-e20e-45e5-ad64-7fa1b902dd70",
   "metadata": {},
   "source": [
    "Finally, we unify columns DepartureZone and ArrivalZone in a column named route and we delete the columns we do not want anymore: ArrivalZone and DepartureZone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e5eaabe-c5b6-4412-ae45-b0804bc177a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.withColumn(\"route\", concat(final_df.DepartureZone, lit(\" \"), final_df.ArrivalZone))\n",
    "#final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c0075d-ae84-4cb0-9d0b-113236c26194",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(\"ArrivalZone\", \"DepartureZone\")\n",
    "#final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712f133-29d2-4a68-bdfb-5a6d72c07e1f",
   "metadata": {},
   "source": [
    "Now, the data is ready: we have the routes followed by the passengers. We create a new dataframe \"study_1\" only with the columns needed to perform the study: Tip_amount and route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cef9b28a-8b55-450a-8168-8ced93fb913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_1 = final_df.select(\"Tip_amount\", \"route\")\n",
    "#study_1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69267d3-f86c-46b4-9e5d-f5c5b528e5b2",
   "metadata": {},
   "source": [
    "To complete the first study, we have decided to calculate the average of tips paid by the passengers on the route.\n",
    "\n",
    "The steps that have been followed are:\n",
    "- groupBy(): In order to classify the tips based on the route\n",
    "- agg(): An aggregate function to calculate the average using avg()\n",
    "- orderBy(): To sort the tips in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86be479-db68-4869-bfcc-502e1e1fa501",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tips = study_1.groupBy('route').agg(round(avg('Tip_amount'), 2).alias('Average_Tip_per_Route')).orderBy('Average_Tip_per_Route', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b06a4f-9ad5-4ab1-9809-6b71ff2dd457",
   "metadata": {},
   "source": [
    "Finally, we show the results and calculate the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d109187e-b2bd-41c4-beb7-c3365eaa1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|               route|Average_Tip_per_Route|\n",
      "+--------------------+---------------------+\n",
      "|           Bronx EWR|                 91.6|\n",
      "|Staten Island Man...|                18.39|\n",
      "|       EWR Manhattan|                16.05|\n",
      "|        EWR Brooklyn|                 15.0|\n",
      "|             EWR EWR|                13.18|\n",
      "|         Unknown EWR|                10.69|\n",
      "|          Queens EWR|                 9.97|\n",
      "|       Manhattan EWR|                 9.35|\n",
      "|        Brooklyn EWR|                 8.59|\n",
      "|      Queens Unknown|                 7.77|\n",
      "|    Brooklyn Unknown|                  6.7|\n",
      "|    Queens Manhattan|                 6.67|\n",
      "|Manhattan Staten ...|                 6.41|\n",
      "|      Bronx Brooklyn|                 5.49|\n",
      "|     Queens Brooklyn|                 5.06|\n",
      "|Queens Staten Island|                 4.23|\n",
      "|    Unknown Brooklyn|                  4.1|\n",
      "|    Manhattan Queens|                 3.76|\n",
      "|   Manhattan Unknown|                 3.75|\n",
      "|        Queens Bronx|                 3.38|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time study 1:  2.828535556793213\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "avg_tips.show() #as it is he action --> measure execution time here\n",
    "end = time.time()\n",
    "exec_time = end  - start\n",
    "print(\"Execution time study 1: \", exec_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c000b-4301-4c16-95bf-a79635749e19",
   "metadata": {},
   "source": [
    "We also transform the data into Pandas in order to plot the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f7c3259-0a99-4a23-9567-bf6426be0d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\navg_tips_pd = avg_tips.toPandas()\\n\\nplt.figure(figsize=(10,6))\\n\\nplt.barh(avg_tips_pd[\"route\"], avg_tips_pd[\"Average_Tip_per_Route\"])\\nplt.xlabel(\"Average Tips\")\\nplt.ylabel(\"Route\")\\nplt.title(\"Average Tip per Route\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "avg_tips_pd = avg_tips.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.barh(avg_tips_pd[\"route\"], avg_tips_pd[\"Average_Tip_per_Route\"])\n",
    "plt.xlabel(\"Average Tips\")\n",
    "plt.ylabel(\"Route\")\n",
    "plt.title(\"Average Tip per Route\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04998257-62ee-4782-9075-bedb2fa4b463",
   "metadata": {},
   "source": [
    "## 2. Average speed of taxis in terms of the hour.\n",
    " \n",
    "\n",
    "### 2.1 Solution implemented using RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b209c-cc9f-4e88-8e1c-abc396c9735d",
   "metadata": {},
   "source": [
    "For this purpose we need:\n",
    "- trip_distance (distance covered by the taxi in a certain route)\n",
    "- tpep_dropoff_datetime - tpep_pickup_datetime (time of a certain route)\n",
    "- tpep_pickup_datetime (taken as the hour to compare speeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea77dd1-eec3-4fd1-962c-b4bc0a0fe8c7",
   "metadata": {},
   "source": [
    "We load the data in a RDD, count the number of rows and show the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "523d6f79-4e50-48cb-995d-d85656f769e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"tripdata_2017_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b86f47a0-7a85-46f7-ad47-6e0677d4a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e959d083-acab-4e1e-9f79-63e6f27e4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdd.take(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3bbbd-bcf1-4601-9993-9f9269cdd2a0",
   "metadata": {},
   "source": [
    "First, we filter the header to get the data we are going to access.\n",
    "Also, we remove the rows with empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "411b3f8f-3999-4075-9b8b-5b1b1e0ba9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = rdd.first()\n",
    "rdd = rdd.filter(lambda x: x != header).filter(lambda x: x != '')\n",
    "#rdd.take(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766414c0-1d6e-450c-8cb7-70750d00578e",
   "metadata": {},
   "source": [
    "Then, we divide the data in columns (by splitting by the ,) and select the three columns we will use, obtaining a list of 3 elements tuples with values of distances (index 4), pickup times (index 1) and dropoff times (index 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa2a2267-346d-4faa-8ea3-1e659ccb7a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3.30', '2017-01-09 11:13:28', '2017-01-09 11:25:45'),\n",
       " ('.90', '2017-01-09 11:32:27', '2017-01-09 11:36:01'),\n",
       " ('1.10', '2017-01-09 11:38:20', '2017-01-09 11:42:05'),\n",
       " ('1.10', '2017-01-09 11:52:13', '2017-01-09 11:57:36'),\n",
       " ('.02', '2017-01-01 00:00:00', '2017-01-01 00:00:00'),\n",
       " ('.50', '2017-01-01 00:00:02', '2017-01-01 00:03:50'),\n",
       " ('7.75', '2017-01-01 00:00:02', '2017-01-01 00:39:22'),\n",
       " ('.80', '2017-01-01 00:00:03', '2017-01-01 00:06:58')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns_rdd = rdd.map(lambda x: (x.split(\",\")[4], x.split(\",\")[1], x.split(\",\")[2]))\n",
    "selected_columns_rdd.take(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f56e1-851a-44a6-9a5e-2222ad2c809c",
   "metadata": {},
   "source": [
    "To calculate the duration of the trips, we do the substraction operation between dropoff and pickup times and add a new \"column\" to the rdd with that data\n",
    "The time is calculated in hours as the distance is in miles, to then calculate the speed as in miles/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecc559b5-429b-4464-94bc-4dfa26cf5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "withDurationRDD = selected_columns_rdd.map(lambda row: (row[0], row[1], row[2], (datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") - datetime.strptime(row[1], \"%Y-%m-%d %H:%M:%S\")).total_seconds()/ 3600.0))\n",
    "#withDurationRDD.take(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f6243-15ce-4239-9d95-0890eeadfb86",
   "metadata": {},
   "source": [
    "To calculate the speed, we divide the distance by the time, add a new \"column\" to the rdd with that data and then we keep in the rdd only the columns we need, that are row[1] = hour of service (pick-up time) and row[4]= speed of the taxi (miles per hour). As some trips last 0 (start and finish at the same time), we add an if condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43dff1c8-9b1f-4806-b49f-54663f9c1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "withSpeedRDD = withDurationRDD.map(lambda row: (row[0], row[1], row[2], row[3], (float(row[0]) / row[3]) if row[3] != 0 else 0.0)) \n",
    "date_speed = withSpeedRDD.map(lambda row: (row[1], row[4]))\n",
    "\n",
    "#date_speed.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4736c-cde6-4710-82e2-a3ad72ed7e2a",
   "metadata": {},
   "source": [
    "Also, we remove the day from the date as it is not meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8db3abc-5eab-4e4b-8695-e90d798c786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_speed = date_speed.map(lambda row: (row[0].split(' ')[1], row[1]))\n",
    "#hour_speed.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fcbee-8fd6-49a0-abfb-6b819748d1e3",
   "metadata": {},
   "source": [
    "Finally, we order the RDD by the speed, to see the possible relationship between hour and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "424640e7-6a36-4f0f-9156-4ddce995c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rdd = hour_speed.sortBy(lambda x: x[1], ascending = False) #sorting by speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5562c81-3bc8-4a0c-9df2-c09f9b821d02",
   "metadata": {},
   "source": [
    "We show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a26d90b0-84b6-4ff0-928f-f1d37bba2a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_hour, speed\n",
      "Execution time study 2, RDDs implementation:  20.509045124053955\n"
     ]
    }
   ],
   "source": [
    "print(\"pickup_hour, speed\")\n",
    "start = time.time()\n",
    "final_rdd.collect()\n",
    "end = time.time()\n",
    "exec_time = end  - start\n",
    "print(\"Execution time study 2, RDDs implementation: \", exec_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72e175-45f9-493b-961b-26c2399d51de",
   "metadata": {},
   "source": [
    "### 2.2 Solution implemented using dataframes\n",
    "\n",
    "For this implementation, we need the same columns as with the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eea94fd-287d-41de-aa62-a4f8f751cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.printSchema() #list of all columns that are part of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595c3c4-4d39-43a1-a1e8-07cd0ed5f654",
   "metadata": {},
   "source": [
    "First, we select the columns we want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b536a724-fd7e-46a6-bede-44a6fa68d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_2 = df3.select(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"trip_distance\")\n",
    "#study_2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f545cba-cfa0-4763-a773-dbb48d6ca735",
   "metadata": {},
   "source": [
    "Then, we create a new column \"duration\" by susbtracting pickup times from dropoff times\n",
    "We use the function unix_timestamp to get the outcome in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcb2560c-078c-4d95-b8a3-10680b41e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_2 = study_2.withColumn('duration_seconds', unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\"))\n",
    "\n",
    "duration_df = study_2.withColumn('duration_hours', study_2[\"duration_seconds\"] / 3600)\n",
    "\n",
    "#duration_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba8331-9429-4e9f-be3b-acfcfb507c0a",
   "metadata": {},
   "source": [
    "We create the column \"speed\" by dividing the \"trip_distance\" and the \"duration\" columns.\n",
    "As the distance is in miles and the duration is in hours, the speed will be in miles per hour\n",
    "We add the when function to avoid null values when dividing by duration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dbeed00-5a36-4918-bf01-2edd8610ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df = duration_df.withColumn('speed', when(duration_df[\"duration_hours\"] == 0, 0)\n",
    "                                       .otherwise(duration_df[\"trip_distance\"] / duration_df[\"duration_hours\"]))\n",
    "#speed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c53c72-6a68-48ea-bea6-22d793532a16",
   "metadata": {},
   "source": [
    "We remove the day from the date as it is not meaningful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73867a30-1dc9-42e6-8368-d830945fff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'tpep_pickup_datetime' column by the space character\n",
    "split_col = split(speed_df['tpep_pickup_datetime'], ' ')\n",
    "\n",
    "# Create new columns for date and time\n",
    "speed_df = speed_df.withColumn(\"hour\", split_col.getItem(1))\n",
    "#speed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396ae4c-bde3-4efa-b339-e4e40c9118d4",
   "metadata": {},
   "source": [
    "We drop the columns that we no longer need before ordering the data for computational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abc5ca1a-1093-4a8c-8105-8fe53fa72edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that we no longer need \n",
    "final_columns = speed_df.drop(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"trip_distance\", \"duration_seconds\", \"duration_hours\")\n",
    "#final_columns.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0e8b8-a126-48d5-95b5-9d74905b5898",
   "metadata": {},
   "source": [
    "Finally, we order by the speed to see the possible relationship between hour and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "368b08f8-0d98-4bfb-8eb1-60e232b6363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+\n",
      "|             speed|    hour|\n",
      "+------------------+--------+\n",
      "|           73800.0|23:02:31|\n",
      "|           70560.0|16:35:18|\n",
      "|           68760.0|19:39:26|\n",
      "| 62639.99999999999|22:59:52|\n",
      "|           32760.0|23:48:05|\n",
      "|           24210.0|20:50:01|\n",
      "|           22920.0|17:01:09|\n",
      "|           21600.0|22:46:25|\n",
      "|20879.999999999996|16:57:12|\n",
      "|20879.999999999996|21:22:57|\n",
      "|           20760.0|09:54:42|\n",
      "|           20760.0|16:01:32|\n",
      "|           20340.0|08:37:32|\n",
      "|           19620.0|04:49:02|\n",
      "|           19260.0|04:21:37|\n",
      "|           17280.0|01:03:11|\n",
      "|           16596.0|00:41:06|\n",
      "|16109.999999999998|00:02:40|\n",
      "|15840.000000000002|02:49:11|\n",
      "|           15480.0|19:33:45|\n",
      "+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time study 2, dataframe implementation:  3.036545515060425\n"
     ]
    }
   ],
   "source": [
    "final_study_2 = final_columns.orderBy(\"speed\", ascending = False)\n",
    "start = time.time()\n",
    "final_study_2.show()\n",
    "end = time.time()\n",
    "exec_time = end  - start\n",
    "print(\"Execution time study 2, dataframe implementation: \", exec_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3694e6-f108-4d95-9ba6-ce40c900a815",
   "metadata": {},
   "source": [
    "### 2.3 Solution implemented using SQL\n",
    "\n",
    "Once again, we need the same 3 columns\n",
    "- Using the columns tpep_pickup_datetime and tpep_dropoff_datetime we calculate the duration of the trip (substraction). To do it, we use the function DATEDIFF, that returns the time in seconds.\n",
    "- From the column tpep_pickup_datetime, we extract the time using DATE_FORMAT as 'hour'. \n",
    "- Using the column trip_distance and the duration we calculate the speed, avoiding null values\n",
    "- We select speed and 'hour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aee40e18-245c-4625-97a3-2b097018a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.createOrReplaceTempView('trips') #DESIGN AN ALIAS (a custom name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dded1ab-9fd2-44ad-a466-8f41e39a0df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+\n",
      "|             speed|    hour|\n",
      "+------------------+--------+\n",
      "|           73800.0|23:02:31|\n",
      "|           70560.0|16:35:18|\n",
      "|           68760.0|19:39:26|\n",
      "| 62639.99999999999|22:59:52|\n",
      "|           32760.0|23:48:05|\n",
      "|           24210.0|20:50:01|\n",
      "|           22920.0|17:01:09|\n",
      "|           21600.0|22:46:25|\n",
      "|20879.999999999996|16:57:12|\n",
      "|20879.999999999996|21:22:57|\n",
      "|           20760.0|09:54:42|\n",
      "|           20760.0|16:01:32|\n",
      "|           20340.0|08:37:32|\n",
      "|           19620.0|04:49:02|\n",
      "|           19260.0|04:21:37|\n",
      "|           17280.0|01:03:11|\n",
      "|           16596.0|00:41:06|\n",
      "|16109.999999999998|00:02:40|\n",
      "|15840.000000000002|02:49:11|\n",
      "|           15480.0|19:33:45|\n",
      "+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time study 2, SQL implementation:  3.942714214324951\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT \n",
    "            trip_distance / (DATEDIFF(SECOND, tpep_pickup_datetime, tpep_dropoff_datetime) / 3600) AS speed,\n",
    "            DATE_FORMAT(tpep_pickup_datetime, 'HH:mm:ss') AS hour\n",
    "        FROM trips\n",
    "    )\n",
    "    WHERE speed IS NOT NULL\n",
    "    ORDER BY speed DESC\n",
    "\"\"\").show()\n",
    "end = time.time()\n",
    "exec_time = end  - start\n",
    "print(\"Execution time study 2, SQL implementation: \", exec_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66e197-eda4-4262-a2c0-a554a1ca77c2",
   "metadata": {},
   "source": [
    "## 3. Average trip distance depending on the number of passengers\n",
    "\n",
    "### Solution implemented using SQL\n",
    "\n",
    "For this, we need:\n",
    "- trip_distance\n",
    "- passenger_count\n",
    "\n",
    "Once selected, we need to calculate the average distances for every different number of passengers (grouping by the passengers number). We remove the data for 0 passengers as it does not make sense for the interpretation of taxi trips data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14459636-6afc-4a2e-a5af-0d03f2408fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.createOrReplaceTempView('trips') #DESIGN AN ALIAS (a custom name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37d46cb1-eccd-44ef-9cd4-c0c17148385c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+------------------+------------------+\n",
      "|passenger_count|avg(trip_distance)|max(trip_distance)|min(trip_distance)|\n",
      "+---------------+------------------+------------------+------------------+\n",
      "|              1| 2.995511475864654|             120.6|               0.0|\n",
      "|              2|   3.1123642396984|              86.3|               0.0|\n",
      "|              3| 3.045738847281015|            139.17|               0.0|\n",
      "|              4| 3.087570436042792|             151.7|               0.0|\n",
      "|              5|3.1499190421663785|             50.15|               0.0|\n",
      "|              6|3.1370771564503857|              79.0|               0.0|\n",
      "|              7|               0.0|               0.0|               0.0|\n",
      "|              8|               0.0|               0.0|               0.0|\n",
      "|              9|               0.0|               0.0|               0.0|\n",
      "+---------------+------------------+------------------+------------------+\n",
      "\n",
      "Execution time study 3:  1.6736044883728027\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "spark.sql(\"SELECT passenger_count, AVG(trip_distance), MAX(trip_distance), MIN(trip_distance) FROM trips WHERE passenger_count !=0 GROUP BY passenger_count ORDER BY passenger_count\").show()\n",
    "end = time.time()\n",
    "exec_time = end  - start\n",
    "print(\"Execution time study 3: \", exec_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc36aa9-8aea-4147-b1bb-dccdb0d5d3c8",
   "metadata": {},
   "source": [
    "# 4. Results\n",
    "\n",
    "## 4.1 Execution times\n",
    "We save in lists the values of the execution time of every implementation of the 3 studies for every number of available cores (1, 2, 3 or 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cf4a598-e897-40e8-9ee9-5568bb4be34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping execution time in every execution\n",
    "exec_times_1 = [3.3378396034240723,2.3377509117126465,2.236996650695801,2.1290998458862305,1.8683526515960693,1.8208472728729248,1.9524621963500977,1.928175449371338] #with every different number of cores\n",
    "exec_times_2_1 = [25.526318311691284,16.14290690422058,11.482961893081665,12.153632164001465,12.354135513305664,11.921333074569702,12.73586392402649,12.244611024856567]#RDD\n",
    "exec_times_2_2 = [4.21743631362915,2.58328914642334,2.292405605316162,2.2860047817230225,2.1757242679595947,1.7817332744598389,1.967207431793213,2.1478772163391113]#dataframes\n",
    "exec_times_2_3 = [4.309316873550415,2.8333113193511963,2.794114112854004,2.3724422454833984,2.381791114807129,2.024615526199341,1.9099664688110352,2.079253911972046]#SQL\n",
    "exec_times_3 = [2.1889734268188477,1.4472410678863525,1.0829746723175049,1.136519193649292,1.0748541355133057,1.1149506568908691,1.1417241096496582,0.9539737701416016]\n",
    "\n",
    "#cores_num = np.range(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
